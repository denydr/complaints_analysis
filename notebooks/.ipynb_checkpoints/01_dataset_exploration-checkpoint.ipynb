{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e465ed1c-8683-4065-a435-8aef7152b34a",
   "metadata": {},
   "source": [
    "**Selected Dataset:**  *Mach M√ºnchen Besser ‚Äì Open311 GeoReport v2* dataset,  \n",
    "published by the **City of Munich (Landeshauptstadt M√ºnchen)**.  \n",
    "It contains anonymized **citizen complaints and issue reports** submitted via the city‚Äôs official Open311 API,  \n",
    "including unstructured text fields (`description`) and structured metadata (`service_name`, `status`, `requested_datetime`, etc.).  \n",
    "\n",
    "**Source:** [https://machmuenchenbesser.de/georeport/v2/](https://machmuenchenbesser.de/georeport/v2/)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8632c1-81b7-44df-afb2-64c9b91c6172",
   "metadata": {},
   "source": [
    "### (1) Loading Dataset & Displaying Unique Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7b08f1-16aa-41b4-8418-ce20ba9b085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset:\n",
      "['service_request_id', 'title', 'description', 'lat', 'long', 'address_string', 'service_name', 'requested_datetime', 'updated_datetime', 'status', 'media_url', 'status_note', 'service_code'] \n",
      "\n",
      "Example rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>address_string</th>\n",
       "      <th>service_name</th>\n",
       "      <th>requested_datetime</th>\n",
       "      <th>updated_datetime</th>\n",
       "      <th>status</th>\n",
       "      <th>media_url</th>\n",
       "      <th>status_note</th>\n",
       "      <th>service_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63656-2025</td>\n",
       "      <td>#63656-2025 Leuchte ausgefallen</td>\n",
       "      <td>Der Lichtmast funktioniert schon etwas l√§nger ...</td>\n",
       "      <td>48.088190</td>\n",
       "      <td>11.489650</td>\n",
       "      <td>81476 M√ºnchen, Lechbrucker Stra√üe 19</td>\n",
       "      <td>Leuchte ausgefallen</td>\n",
       "      <td>2025-10-10T19:57:13+02:00</td>\n",
       "      <td>2025-10-10T20:10:01+02:00</td>\n",
       "      <td>open</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>24.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63660-2025</td>\n",
       "      <td>#63660-2025 Leuchte ausgefallen</td>\n",
       "      <td>Mast Nr. 3 komplett dunkel</td>\n",
       "      <td>48.166289</td>\n",
       "      <td>11.590986</td>\n",
       "      <td>80802 M√ºnchen, Dietlindenstra√üe 4</td>\n",
       "      <td>Leuchte ausgefallen</td>\n",
       "      <td>2025-10-11T01:16:13+02:00</td>\n",
       "      <td>2025-10-11T01:40:04+02:00</td>\n",
       "      <td>open</td>\n",
       "      <td>http://machmuenchenbesser.de/sites/default/fil...</td>\n",
       "      <td></td>\n",
       "      <td>24.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63671-2025</td>\n",
       "      <td>#63671-2025 Plakat befindet sich in Sperrgebie...</td>\n",
       "      <td>None</td>\n",
       "      <td>48.152847</td>\n",
       "      <td>11.533646</td>\n",
       "      <td>80634 M√ºnchen, Nymphenburger Stra√üe 160</td>\n",
       "      <td>Plakat befindet sich in Sperrgebiet/Bushaltest...</td>\n",
       "      <td>2025-10-11T10:34:21+02:00</td>\n",
       "      <td>2025-10-20T15:53:59+02:00</td>\n",
       "      <td>open</td>\n",
       "      <td>http://machmuenchenbesser.de/sites/default/fil...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63682-2025</td>\n",
       "      <td>#63682-2025 Plakat befindet sich in Sperrgebie...</td>\n",
       "      <td>None</td>\n",
       "      <td>48.083871</td>\n",
       "      <td>11.517617</td>\n",
       "      <td>81479 M√ºnchen, Aidenbachstra√üe 223</td>\n",
       "      <td>Plakat befindet sich in Sperrgebiet/Bushaltest...</td>\n",
       "      <td>2025-10-11T13:13:20+02:00</td>\n",
       "      <td>2025-12-01T13:20:16+01:00</td>\n",
       "      <td>open</td>\n",
       "      <td>http://machmuenchenbesser.de/sites/default/fil...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63688-2025</td>\n",
       "      <td>#63688-2025 Plakat blockiert Sicht/Stra√üe/Geh-...</td>\n",
       "      <td>None</td>\n",
       "      <td>48.118509</td>\n",
       "      <td>11.574797</td>\n",
       "      <td>81543 M√ºnchen, Kupferhammerstra√üe 2</td>\n",
       "      <td>Plakat blockiert Sicht/Stra√üe/Geh-/Radweg</td>\n",
       "      <td>2025-10-11T14:16:06+02:00</td>\n",
       "      <td>2025-12-08T11:53:08+01:00</td>\n",
       "      <td>closed</td>\n",
       "      <td>http://machmuenchenbesser.de/sites/default/fil...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  service_request_id                                              title  \\\n",
       "0         63656-2025                    #63656-2025 Leuchte ausgefallen   \n",
       "1         63660-2025                    #63660-2025 Leuchte ausgefallen   \n",
       "2         63671-2025  #63671-2025 Plakat befindet sich in Sperrgebie...   \n",
       "3         63682-2025  #63682-2025 Plakat befindet sich in Sperrgebie...   \n",
       "4         63688-2025  #63688-2025 Plakat blockiert Sicht/Stra√üe/Geh-...   \n",
       "\n",
       "                                         description        lat       long  \\\n",
       "0  Der Lichtmast funktioniert schon etwas l√§nger ...  48.088190  11.489650   \n",
       "1                         Mast Nr. 3 komplett dunkel  48.166289  11.590986   \n",
       "2                                               None  48.152847  11.533646   \n",
       "3                                               None  48.083871  11.517617   \n",
       "4                                               None  48.118509  11.574797   \n",
       "\n",
       "                            address_string  \\\n",
       "0     81476 M√ºnchen, Lechbrucker Stra√üe 19   \n",
       "1        80802 M√ºnchen, Dietlindenstra√üe 4   \n",
       "2  80634 M√ºnchen, Nymphenburger Stra√üe 160   \n",
       "3       81479 M√ºnchen, Aidenbachstra√üe 223   \n",
       "4      81543 M√ºnchen, Kupferhammerstra√üe 2   \n",
       "\n",
       "                                        service_name  \\\n",
       "0                                Leuchte ausgefallen   \n",
       "1                                Leuchte ausgefallen   \n",
       "2  Plakat befindet sich in Sperrgebiet/Bushaltest...   \n",
       "3  Plakat befindet sich in Sperrgebiet/Bushaltest...   \n",
       "4          Plakat blockiert Sicht/Stra√üe/Geh-/Radweg   \n",
       "\n",
       "          requested_datetime           updated_datetime  status  \\\n",
       "0  2025-10-10T19:57:13+02:00  2025-10-10T20:10:01+02:00    open   \n",
       "1  2025-10-11T01:16:13+02:00  2025-10-11T01:40:04+02:00    open   \n",
       "2  2025-10-11T10:34:21+02:00  2025-10-20T15:53:59+02:00    open   \n",
       "3  2025-10-11T13:13:20+02:00  2025-12-01T13:20:16+01:00    open   \n",
       "4  2025-10-11T14:16:06+02:00  2025-12-08T11:53:08+01:00  closed   \n",
       "\n",
       "                                           media_url status_note service_code  \n",
       "0                                                                       24.17  \n",
       "1  http://machmuenchenbesser.de/sites/default/fil...                    24.17  \n",
       "2  http://machmuenchenbesser.de/sites/default/fil...                     None  \n",
       "3  http://machmuenchenbesser.de/sites/default/fil...                     None  \n",
       "4  http://machmuenchenbesser.de/sites/default/fil...                     None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests, pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "url = \"https://machmuenchenbesser.de/georeport/v2/requests.json\"\n",
    "end = datetime.now()\n",
    "start = end - timedelta(days=60)\n",
    "\n",
    "params = {\n",
    "    \"start_date\": start.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"end_date\": end.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=params, timeout=60)\n",
    "r.raise_for_status()\n",
    "df = pd.DataFrame(r.json())\n",
    "\n",
    "print(\"Columns in dataset:\")\n",
    "print(df.columns.tolist(), \"\\n\")\n",
    "\n",
    "print(\"Example rows:\")\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d512f78-b8c3-434e-b6a7-c8a05a88036f",
   "metadata": {},
   "source": [
    "From the *Mach M√ºnchen Besser ‚Äì Open311 GeoReport v2* dataset,  \n",
    "only the columns relevant to text-based topic extraction and contextual interpretation are retained.\n",
    "\n",
    "| Column | Purpose | Justification |\n",
    "|:--|:--|:--|\n",
    "| **`description`** | Main complaint text | Contains the citizens‚Äô **unstructured free-text complaints**, forming the **core input** for NLP preprocessing and topic modeling (e.g., LDA, NMF, BERTopic). |\n",
    "| **`service_name`** | Official complaint category | Provides the **city-assigned category label** (e.g., ‚ÄúLeuchte ausgefallen‚Äù). Used later for **validating and comparing** extracted topics against official classifications. |\n",
    "| **`title`** | Short summary | Offers a concise system-generated summary of each complaint. Optional but useful for displaying example cases during result interpretation. |\n",
    "| **`requested_datetime`** | Submission timestamp | Enables **temporal trend analysis** (e.g., frequency of certain issues over time) and filtering by reporting period. |\n",
    "| **`status`** | Complaint state | Distinguishes **open** vs. **closed** cases, supporting additional analysis on unresolved topics. |\n",
    "| **`service_request_id`** | Unique identifier | Maintains a consistent reference for each record when filtering, indexing, or merging results. |\n",
    "\n",
    "All other fields (e.g., `lat`, `long`, `address_string`, `media_url`, `service_code`, `status_note`)  \n",
    "are excluded since they do not contribute to **textual or semantic analysis** and add unnecessary complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9583f5-f866-44ab-97ab-42afe4f738e8",
   "metadata": {},
   "source": [
    "### (2) Dataset Sampling\n",
    "\n",
    "This dataset consolidates **unresolved (open) and resolved (closed) citizen complaints** submitted via the City of Munich‚Äôs *Mach M√ºnchen Besser* Open311 portal within the period **2020-01-01 to 2025-12-01**.  \n",
    "Its purpose is to provide a **time-bounded corpus of open complaints** for NLP analysis (e.g., topic extraction) focused on the most pressing, still-unresolved issues.  \n",
    "To keep the analysis both meaningful and manageable, up to **955 complaints** are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81b4825-5dce-44b4-bbdf-0035643b74cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting 6 year windows | status=open\n",
      "=== Window 1/6: 2020-01-01T00:00:00Z ‚Üí 2021-01-01T00:00:00Z ===\n",
      "  [open  ] fetched   0 (90d): 2020-01-01T00:00:00Z ‚Üí 2020-03-31T00:00:00Z\n",
      "  [open  ] fetched   0 (90d): 2020-03-31T00:00:00Z ‚Üí 2020-06-29T00:00:00Z\n",
      "  [open  ] fetched   0 (90d): 2020-06-29T00:00:00Z ‚Üí 2020-09-27T00:00:00Z\n",
      "  [open  ] fetched   0 (90d): 2020-09-27T00:00:00Z ‚Üí 2020-12-26T00:00:00Z\n",
      "  [open  ] fetched   0 ( 6d): 2020-12-26T00:00:00Z ‚Üí 2021-01-01T00:00:00Z\n",
      "=== Window 2/6: 2021-01-01T00:00:00Z ‚Üí 2022-01-01T00:00:00Z ===\n",
      "  [open  ] fetched   0 (90d): 2021-01-01T00:00:00Z ‚Üí 2021-04-01T00:00:00Z\n",
      "  [open  ] fetched   0 (90d): 2021-04-01T00:00:00Z ‚Üí 2021-06-30T00:00:00Z\n",
      "  [open  ] fetched   1 (90d): 2021-06-30T00:00:00Z ‚Üí 2021-09-28T00:00:00Z\n",
      "  [open  ] fetched   1 (90d): 2021-09-28T00:00:00Z ‚Üí 2021-12-27T00:00:00Z\n",
      "  [open  ] fetched   0 ( 5d): 2021-12-27T00:00:00Z ‚Üí 2022-01-01T00:00:00Z\n",
      "=== Window 3/6: 2022-01-01T00:00:00Z ‚Üí 2023-01-01T00:00:00Z ===\n",
      "  [open  ] fetched   2 (90d): 2022-01-01T00:00:00Z ‚Üí 2022-04-01T00:00:00Z\n",
      "  [open  ] fetched  12 (90d): 2022-04-01T00:00:00Z ‚Üí 2022-06-30T00:00:00Z\n",
      "  [open  ] fetched   1 (90d): 2022-06-30T00:00:00Z ‚Üí 2022-09-28T00:00:00Z\n",
      "  [open  ] fetched   2 (90d): 2022-09-28T00:00:00Z ‚Üí 2022-12-27T00:00:00Z\n",
      "  [open  ] fetched   0 ( 5d): 2022-12-27T00:00:00Z ‚Üí 2023-01-01T00:00:00Z\n",
      "=== Window 4/6: 2023-01-01T00:00:00Z ‚Üí 2024-01-01T00:00:00Z ===\n",
      "  [open  ] fetched   3 (90d): 2023-01-01T00:00:00Z ‚Üí 2023-04-01T00:00:00Z\n",
      "  [open  ] fetched  21 (90d): 2023-04-01T00:00:00Z ‚Üí 2023-06-30T00:00:00Z\n",
      "  [open  ] fetched  12 (90d): 2023-06-30T00:00:00Z ‚Üí 2023-09-28T00:00:00Z\n",
      "  [open  ] fetched   4 (90d): 2023-09-28T00:00:00Z ‚Üí 2023-12-27T00:00:00Z\n",
      "  [open  ] fetched   1 ( 5d): 2023-12-27T00:00:00Z ‚Üí 2024-01-01T00:00:00Z\n",
      "=== Window 5/6: 2024-01-01T00:00:00Z ‚Üí 2025-01-01T00:00:00Z ===\n",
      "  [open  ] fetched   5 (90d): 2024-01-01T00:00:00Z ‚Üí 2024-03-31T00:00:00Z\n",
      "  [open  ] fetched  19 (90d): 2024-03-31T00:00:00Z ‚Üí 2024-06-29T00:00:00Z\n",
      "  [open  ] fetched   9 (90d): 2024-06-29T00:00:00Z ‚Üí 2024-09-27T00:00:00Z\n",
      "  [open  ] fetched  70 (90d): 2024-09-27T00:00:00Z ‚Üí 2024-12-26T00:00:00Z\n",
      "  [open  ] fetched   0 ( 6d): 2024-12-26T00:00:00Z ‚Üí 2025-01-01T00:00:00Z\n",
      "=== Window 6/6: 2025-01-01T00:00:00Z ‚Üí 2025-12-01T00:00:00Z ===\n",
      "  [open  ] fetched 100 (90d): 2025-01-01T00:00:00Z ‚Üí 2025-04-01T00:00:00Z\n",
      "  [open  ] fetched  74 (45d): 2025-01-01T00:00:00Z ‚Üí 2025-02-15T00:00:00Z\n",
      "  [open  ] fetched  42 (45d): 2025-02-15T00:00:00Z ‚Üí 2025-04-01T00:00:00Z\n",
      "  [open  ] fetched  36 (90d): 2025-04-01T00:00:00Z ‚Üí 2025-06-30T00:00:00Z\n",
      "  [open  ] fetched  67 (90d): 2025-06-30T00:00:00Z ‚Üí 2025-09-28T00:00:00Z\n",
      "  [open  ] fetched 100 (64d): 2025-09-28T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [open  ] fetched  55 (32d): 2025-09-28T00:00:00Z ‚Üí 2025-10-30T00:00:00Z\n",
      "  [open  ] fetched 100 (32d): 2025-10-30T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [open  ] fetched  59 (16d): 2025-10-30T00:00:00Z ‚Üí 2025-11-15T00:00:00Z\n",
      "  [open  ] fetched  96 (16d): 2025-11-15T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "\n",
      "Collecting 6 year windows | status=closed\n",
      "=== Window 1/6: 2020-01-01T00:00:00Z ‚Üí 2021-01-01T00:00:00Z ===\n",
      "  [closed] fetched   0 (90d): 2020-01-01T00:00:00Z ‚Üí 2020-03-31T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2020-03-31T00:00:00Z ‚Üí 2020-06-29T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2020-06-29T00:00:00Z ‚Üí 2020-09-27T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2020-09-27T00:00:00Z ‚Üí 2020-12-26T00:00:00Z\n",
      "  [closed] fetched   0 ( 6d): 2020-12-26T00:00:00Z ‚Üí 2021-01-01T00:00:00Z\n",
      "=== Window 2/6: 2021-01-01T00:00:00Z ‚Üí 2022-01-01T00:00:00Z ===\n",
      "  [closed] fetched   0 (90d): 2021-01-01T00:00:00Z ‚Üí 2021-04-01T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2021-04-01T00:00:00Z ‚Üí 2021-06-30T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2021-06-30T00:00:00Z ‚Üí 2021-09-28T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2021-09-28T00:00:00Z ‚Üí 2021-12-27T00:00:00Z\n",
      "  [closed] fetched   0 ( 5d): 2021-12-27T00:00:00Z ‚Üí 2022-01-01T00:00:00Z\n",
      "=== Window 3/6: 2022-01-01T00:00:00Z ‚Üí 2023-01-01T00:00:00Z ===\n",
      "  [closed] fetched   0 (90d): 2022-01-01T00:00:00Z ‚Üí 2022-04-01T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2022-04-01T00:00:00Z ‚Üí 2022-06-30T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2022-06-30T00:00:00Z ‚Üí 2022-09-28T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2022-09-28T00:00:00Z ‚Üí 2022-12-27T00:00:00Z\n",
      "  [closed] fetched   0 ( 5d): 2022-12-27T00:00:00Z ‚Üí 2023-01-01T00:00:00Z\n",
      "=== Window 4/6: 2023-01-01T00:00:00Z ‚Üí 2024-01-01T00:00:00Z ===\n",
      "  [closed] fetched   0 (90d): 2023-01-01T00:00:00Z ‚Üí 2023-04-01T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2023-04-01T00:00:00Z ‚Üí 2023-06-30T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2023-06-30T00:00:00Z ‚Üí 2023-09-28T00:00:00Z\n",
      "  [closed] fetched   2 (90d): 2023-09-28T00:00:00Z ‚Üí 2023-12-27T00:00:00Z\n",
      "  [closed] fetched   0 ( 5d): 2023-12-27T00:00:00Z ‚Üí 2024-01-01T00:00:00Z\n",
      "=== Window 5/6: 2024-01-01T00:00:00Z ‚Üí 2025-01-01T00:00:00Z ===\n",
      "  [closed] fetched   0 (90d): 2024-01-01T00:00:00Z ‚Üí 2024-03-31T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2024-03-31T00:00:00Z ‚Üí 2024-06-29T00:00:00Z\n",
      "  [closed] fetched   1 (90d): 2024-06-29T00:00:00Z ‚Üí 2024-09-27T00:00:00Z\n",
      "  [closed] fetched   0 (90d): 2024-09-27T00:00:00Z ‚Üí 2024-12-26T00:00:00Z\n",
      "  [closed] fetched   0 ( 6d): 2024-12-26T00:00:00Z ‚Üí 2025-01-01T00:00:00Z\n",
      "=== Window 6/6: 2025-01-01T00:00:00Z ‚Üí 2025-12-01T00:00:00Z ===\n",
      "  [closed] fetched   2 (90d): 2025-01-01T00:00:00Z ‚Üí 2025-04-01T00:00:00Z\n",
      "  [closed] fetched   1 (90d): 2025-04-01T00:00:00Z ‚Üí 2025-06-30T00:00:00Z\n",
      "  [closed] fetched   4 (90d): 2025-06-30T00:00:00Z ‚Üí 2025-09-28T00:00:00Z\n",
      "  [closed] fetched 100 (64d): 2025-09-28T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [closed] fetched  47 (32d): 2025-09-28T00:00:00Z ‚Üí 2025-10-30T00:00:00Z\n",
      "  [closed] fetched 100 (32d): 2025-10-30T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [closed] fetched 100 (16d): 2025-10-30T00:00:00Z ‚Üí 2025-11-15T00:00:00Z\n",
      "  [closed] fetched  76 ( 8d): 2025-10-30T00:00:00Z ‚Üí 2025-11-07T00:00:00Z\n",
      "  [closed] fetched 100 ( 8d): 2025-11-07T00:00:00Z ‚Üí 2025-11-15T00:00:00Z\n",
      "  [closed] fetched  62 ( 4d): 2025-11-07T00:00:00Z ‚Üí 2025-11-11T00:00:00Z\n",
      "  [closed] fetched 100 ( 4d): 2025-11-11T00:00:00Z ‚Üí 2025-11-15T00:00:00Z\n",
      "  [closed] fetched 100 (16d): 2025-11-15T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [closed] fetched 100 ( 8d): 2025-11-15T00:00:00Z ‚Üí 2025-11-23T00:00:00Z\n",
      "  [closed] fetched 100 ( 4d): 2025-11-15T00:00:00Z ‚Üí 2025-11-19T00:00:00Z\n",
      "  [closed] fetched  78 ( 4d): 2025-11-19T00:00:00Z ‚Üí 2025-11-23T00:00:00Z\n",
      "  [closed] fetched 100 ( 8d): 2025-11-23T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "  [closed] fetched  51 ( 4d): 2025-11-23T00:00:00Z ‚Üí 2025-11-27T00:00:00Z\n",
      "  [closed] fetched  74 ( 4d): 2025-11-27T00:00:00Z ‚Üí 2025-12-01T00:00:00Z\n",
      "\n",
      "Merge+dedup: 1190 ‚Üí 1190 unique complaints\n",
      "Split: {'open': 592, 'closed': 598}\n",
      "Dropped rows with empty/placeholder descriptions: 235 (kept 955)\n",
      "Saved 955 rows ‚Üí /Users/dd/PycharmProjects/complaints_analysis/datasets/raw/munich_open311_2020-01-01_to_2025-12-01.csv\n"
     ]
    }
   ],
   "source": [
    "# Munich Open311 ‚Äì fetch OPEN and CLOSED separately, then merge + dedupe, then drop empty descriptions\n",
    "import os, time, requests, pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "BASE_URL = \"https://machmuenchenbesser.de/georeport/v2/requests.json\"\n",
    "\n",
    "START_ISO = \"2020-01-01T00:00:00Z\"   # inclusive\n",
    "END_ISO   = \"2025-12-01T00:00:00Z\"   # exclusive\n",
    "KEEP_COLS = [\"service_request_id\",\"service_name\",\"title\",\"description\",\"requested_datetime\",\"status\"]\n",
    "\n",
    "# Heuristics\n",
    "MAX_WINDOW_DAYS  = 90\n",
    "MIN_WINDOW_DAYS  = 7\n",
    "CAP_SUSPECT      = 100\n",
    "REQUEST_SLEEP    = 0.12\n",
    "TIMEOUT_SEC      = 45\n",
    "\n",
    "def to_utc(s: str) -> datetime:\n",
    "    return datetime.fromisoformat(s.replace(\"Z\",\"+00:00\")).astimezone(timezone.utc)\n",
    "\n",
    "def iso(dt: datetime) -> str:\n",
    "    return dt.astimezone(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "def make_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=4, backoff_factor=0.6,\n",
    "                    status_forcelist=(429,500,502,503,504),\n",
    "                    allowed_methods=frozenset([\"GET\"]))\n",
    "    ad = HTTPAdapter(max_retries=retries, pool_connections=8, pool_maxsize=8)\n",
    "    s.mount(\"http://\", ad); s.mount(\"https://\", ad)\n",
    "    s.headers.update({\"Accept\":\"application/json\",\"User-Agent\":\"munich-open311-nlp/fetch-split/1.0\"})\n",
    "    return s\n",
    "\n",
    "def fetch_slice(session: requests.Session, start_dt: datetime, end_dt: datetime, status: str) -> list[dict]:\n",
    "    params = {\"start_date\": iso(start_dt), \"end_date\": iso(end_dt), \"status\": status}\n",
    "    r = session.get(BASE_URL, params=params, timeout=TIMEOUT_SEC)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    if isinstance(data, list): return data\n",
    "    if isinstance(data, dict):\n",
    "        for v in data.values():\n",
    "            if isinstance(v, list): return v\n",
    "    return []\n",
    "\n",
    "def collect_window(session: requests.Session, start_dt: datetime, end_dt: datetime, status: str) -> list[dict]:\n",
    "    span_days = max(int((end_dt - start_dt).total_seconds() // 86400), 0)\n",
    "    if span_days > MAX_WINDOW_DAYS:\n",
    "        mid = start_dt + timedelta(days=MAX_WINDOW_DAYS)\n",
    "        return (collect_window(session, start_dt, mid, status)\n",
    "                + collect_window(session, mid, end_dt, status))\n",
    "\n",
    "    rows = fetch_slice(session, start_dt, end_dt, status)\n",
    "    print(f\"  [{status:6}] fetched {len(rows):3d} ({span_days:2d}d): {iso(start_dt)} ‚Üí {iso(end_dt)}\")\n",
    "    time.sleep(REQUEST_SLEEP)\n",
    "\n",
    "    if len(rows) >= CAP_SUSPECT and span_days > MIN_WINDOW_DAYS:\n",
    "        half = (end_dt - start_dt) / 2\n",
    "        mid = start_dt + half\n",
    "        # guard against degenerate midpoint\n",
    "        if mid <= start_dt + timedelta(seconds=1) or mid >= end_dt - timedelta(seconds=1):\n",
    "            shrink = timedelta(days=min(MIN_WINDOW_DAYS, span_days//2 or 1))\n",
    "            mid = min(start_dt + shrink, end_dt - timedelta(seconds=1))\n",
    "        left  = collect_window(session, start_dt, mid, status)\n",
    "        right = collect_window(session, mid, end_dt, status)\n",
    "        return left + right\n",
    "\n",
    "    return rows\n",
    "\n",
    "def build_year_windows(start_iso: str, end_iso: str) -> list[tuple[datetime, datetime]]:\n",
    "    s, e = to_utc(start_iso), to_utc(end_iso)\n",
    "    out, cur = [], s\n",
    "    while cur < e:\n",
    "        year_end = datetime(cur.year + 1, 1, 1, tzinfo=timezone.utc)\n",
    "        nxt = min(year_end, e)\n",
    "        out.append((cur, nxt))\n",
    "        cur = nxt\n",
    "    return out\n",
    "\n",
    "def collect_status(status: str) -> pd.DataFrame:\n",
    "    session = make_session()\n",
    "    outer = build_year_windows(START_ISO, END_ISO)\n",
    "    print(f\"\\nCollecting {len(outer)} year windows | status={status}\")\n",
    "    all_rows = []\n",
    "    for i, (ws, we) in enumerate(outer, 1):\n",
    "        print(f\"=== Window {i}/{len(outer)}: {iso(ws)} ‚Üí {iso(we)} ===\")\n",
    "        all_rows += collect_window(session, ws, we, status)\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "    # Deduplicate by ID, keep latest by requested_datetime\n",
    "    df = df.sort_values(\"requested_datetime\", kind=\"stable\").drop_duplicates(\"service_request_id\", keep=\"last\")\n",
    "    # Normalize and keep requested status only (defensive)\n",
    "    df[\"status_norm\"] = df[\"status\"].astype(str).str.lower().str.strip()\n",
    "    df = df[df[\"status_norm\"] == status.lower()].drop(columns=[\"status_norm\"])\n",
    "    return df[KEEP_COLS].reset_index(drop=True)\n",
    "\n",
    "# RUN: fetch separately, then merge\n",
    "df_open   = collect_status(\"open\")\n",
    "df_closed = collect_status(\"closed\")\n",
    "\n",
    "df_all = pd.concat([df_open, df_closed], ignore_index=True)\n",
    "before = len(df_all)\n",
    "df_all = df_all.sort_values(\"requested_datetime\", kind=\"stable\").drop_duplicates(\"service_request_id\", keep=\"last\")\n",
    "print(f\"\\nMerge+dedup: {before} ‚Üí {len(df_all)} unique complaints\")\n",
    "print(\"Split:\", {\"open\": len(df_open), \"closed\": len(df_closed)})\n",
    "\n",
    "# Drop rows with empty descriptions \n",
    "desc_before = len(df_all)\n",
    "\n",
    "s = df_all[\"description\"]                # original series\n",
    "mask_nonempty = s.notna()                # keep only real non-NaN\n",
    "s_norm = (\n",
    "    s[mask_nonempty]\n",
    "      .astype(str)\n",
    "      .str.replace(u\"\\xa0\", \" \", regex=False)   # remove NBSP\n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)     # collapse whitespace\n",
    "      .str.strip()\n",
    ")\n",
    "\n",
    "# valid text = not empty and not a placeholder like \"nan\"/\"none\"\n",
    "valid = s_norm.ne(\"\") & ~s_norm.str.lower().isin({\"nan\", \"none\", \"null\"})\n",
    "\n",
    "# build final mask over original index\n",
    "final_mask = pd.Series(False, index=df_all.index)\n",
    "final_mask.loc[s_norm.index] = valid\n",
    "\n",
    "df_all = df_all[final_mask].reset_index(drop=True)\n",
    "print(f\"Dropped rows with empty/placeholder descriptions: {desc_before - len(df_all)} (kept {len(df_all)})\")\n",
    "\n",
    "# Save (no-empty-descriptions version)\n",
    "out_dir = \"/Users/dd/PycharmProjects/complaints_analysis/datasets/raw\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "fname = f\"munich_open311_{START_ISO[:10]}_to_{END_ISO[:10]}.csv\"\n",
    "path = os.path.join(out_dir, fname)\n",
    "df_all.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "print(f\"Saved {len(df_all)} rows ‚Üí {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db56fd29-f04f-4735-8882-de6c7ee33602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates found: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/dd/PycharmProjects/complaints_analysis/datasets/raw/munich_open311_2020-01-01_to_2025-12-01.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Check for duplicated complaint IDs\n",
    "dupe_mask = df[\"service_request_id\"].duplicated(keep=False)\n",
    "num_dupes = dupe_mask.sum()\n",
    "\n",
    "print(f\"Total duplicates found: {num_dupes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e7d7a7-161d-4c92-bcaf-ffe77ca8952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Total complaints: 955\n",
      "‚ö†Ô∏è Empty descriptions: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (adjust path as needed)\n",
    "path = \"/Users/dd/PycharmProjects/complaints_analysis/datasets/raw/munich_open311_2020-01-01_to_2025-12-01.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Identify empty or missing descriptions\n",
    "empty_mask = df[\"description\"].isna() | df[\"description\"].astype(str).str.strip().eq(\"\")\n",
    "\n",
    "# Summary stats\n",
    "total_rows = len(df)\n",
    "empty_count = empty_mask.sum()\n",
    "percent_empty = (empty_count / total_rows) * 100\n",
    "\n",
    "print(f\"üßæ Total complaints: {total_rows}\")\n",
    "print(f\"‚ö†Ô∏è Empty descriptions: {empty_count} ({percent_empty:.2f}%)\")\n",
    "\n",
    "# Optional: show some exampless\n",
    "if empty_count > 0:\n",
    "    print(\"\\nExamples of rows with empty descriptions:\")\n",
    "    display(df.loc[empty_mask, [\"service_request_id\", \"service_name\", \"title\", \"status\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655f301-8641-4c84-bd62-7e759c371a7b",
   "metadata": {},
   "source": [
    "### (3) Saving Ready-For-Preprocessing Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa97f89-af62-4676-b8a2-73da8903e9b5",
   "metadata": {},
   "source": [
    "* In order to use the data for subsequent cleaning, a new csv is saved, preserving only the complaint description and the complaint ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e156f2d7-c3cf-41fe-a004-99ebd2f9e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with empty descriptions. Kept 904 valid complaints.\n",
      "‚úÖ Saved filtered dataset ‚Üí /Users/dd/PycharmProjects/complaints_analysis/datasets/raw/complaints_munich_open311__2020-2025.csv\n",
      "Columns: ['service_request_id', 'description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Paths ---\n",
    "IN_PATH = \"/Users/dd/PycharmProjects/complaints_analysis/datasets/raw/munich_open311_2020-01-01_to_2025-12-01.csv\"\n",
    "OUT_DIR = \"/Users/dd/PycharmProjects/complaints_analysis/datasets/raw\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"complaints_munich_open311__2020-2025.csv\")\n",
    "\n",
    "# --- Load dataset ---\n",
    "df = pd.read_csv(IN_PATH, encoding=\"utf-8\")\n",
    "\n",
    "# --- Keep only relevant columns ---\n",
    "keep_cols = [\"service_request_id\", \"description\"]\n",
    "missing = [c for c in keep_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns in source CSV: {missing}\")\n",
    "\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# --- Drop empty or null descriptions ---\n",
    "before = len(df)\n",
    "df[\"description\"] = df[\"description\"].astype(str)\n",
    "df = df[df[\"description\"].str.strip().ne(\"\") & df[\"description\"].notna()].reset_index(drop=True)\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Dropped {before - after} rows with empty descriptions. Kept {after} valid complaints.\")\n",
    "\n",
    "# --- Save the reduced dataset ---\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "df.to_csv(OUT_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"‚úÖ Saved filtered dataset ‚Üí {OUT_PATH}\")\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
