{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35755758-d74c-4a68-ae93-89fc3c6750a5",
   "metadata": {},
   "source": [
    "## Cleaning Checkups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ea8ebc0-e696-41fb-b6d2-12141b8cea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c103d3c-7eb8-4054-9fe7-3c0530c96084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (926, 4)\n",
      "\n",
      "NaN counts:\n",
      "lda_description         0\n",
      "bertopic_description    0\n",
      "dtype: int64\n",
      "\n",
      "Empty-string counts:\n",
      "  LDA empty:        0\n",
      "  BERTopic empty:   0\n",
      "\n",
      "Rows invalid for BOTH pipelines: 0\n",
      "\n",
      "Literal 'nan' string counts:\n",
      "  LDA:      0\n",
      "  BERTopic: 0\n",
      "\n",
      "LDA token count summary:\n",
      "count    926.000000\n",
      "mean       7.025918\n",
      "std        5.960172\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%       10.000000\n",
      "max       65.000000\n",
      "Name: lda_token_count, dtype: float64\n",
      "\n",
      "BERTopic character length summary:\n",
      "count    926.000000\n",
      "mean      97.791577\n",
      "std       88.034912\n",
      "min        3.000000\n",
      "25%       38.000000\n",
      "50%       70.000000\n",
      "75%      132.000000\n",
      "max      941.000000\n",
      "Name: bertopic_char_len, dtype: float64\n",
      "\n",
      "✅ Cleaning sanity checks passed. Data is safe for vectorization & topic modeling.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from config import CLEANED_COMPLAINTS_FILE\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Load cleaned data\n",
    "# -------------------------------------------------\n",
    "df = pd.read_csv(CLEANED_COMPLAINTS_FILE)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) NaN checks\n",
    "# -------------------------------------------------\n",
    "nan_counts = df[[\"lda_description\", \"bertopic_description\"]].isna().sum()\n",
    "print(\"\\nNaN counts:\")\n",
    "print(nan_counts)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Empty / whitespace-only checks\n",
    "# -------------------------------------------------\n",
    "empty_lda = (df[\"lda_description\"].fillna(\"\").str.strip() == \"\").sum()\n",
    "empty_bertopic = (df[\"bertopic_description\"].fillna(\"\").str.strip() == \"\").sum()\n",
    "\n",
    "print(\"\\nEmpty-string counts:\")\n",
    "print(f\"  LDA empty:        {empty_lda}\")\n",
    "print(f\"  BERTopic empty:   {empty_bertopic}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Rows invalid for BOTH pipelines (should be 0)\n",
    "# -------------------------------------------------\n",
    "invalid_rows = df[\n",
    "    (df[\"lda_description\"].fillna(\"\").str.strip() == \"\") &\n",
    "    (df[\"bertopic_description\"].fillna(\"\").str.strip() == \"\")\n",
    "]\n",
    "\n",
    "print(f\"\\nRows invalid for BOTH pipelines: {len(invalid_rows)}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Accidental 'nan' strings (rare but dangerous)\n",
    "# -------------------------------------------------\n",
    "nan_string_lda = (df[\"lda_description\"].astype(str).str.lower() == \"nan\").sum()\n",
    "nan_string_bt = (df[\"bertopic_description\"].astype(str).str.lower() == \"nan\").sum()\n",
    "\n",
    "print(\"\\nLiteral 'nan' string counts:\")\n",
    "print(f\"  LDA:      {nan_string_lda}\")\n",
    "print(f\"  BERTopic: {nan_string_bt}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5) Token / length sanity checks\n",
    "# -------------------------------------------------\n",
    "df[\"lda_token_count\"] = df[\"lda_description\"].fillna(\"\").str.split().str.len()\n",
    "df[\"bertopic_char_len\"] = df[\"bertopic_description\"].fillna(\"\").str.len()\n",
    "\n",
    "print(\"\\nLDA token count summary:\")\n",
    "print(df[\"lda_token_count\"].describe())\n",
    "\n",
    "print(\"\\nBERTopic character length summary:\")\n",
    "print(df[\"bertopic_char_len\"].describe())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6) Final hard assertions (fail fast)\n",
    "# -------------------------------------------------\n",
    "assert nan_counts.sum() == 0, \"❌ NaN values detected\"\n",
    "assert nan_string_lda == 0 and nan_string_bt == 0, \"❌ Literal 'nan' strings detected\"\n",
    "assert len(invalid_rows) == 0, \"❌ Rows empty for both LDA and BERTopic\"\n",
    "\n",
    "print(\"\\n✅ Cleaning sanity checks passed. Data is safe for vectorization & topic modeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c66bf1-115f-46b4-a781-a076920fef33",
   "metadata": {},
   "source": [
    "### (1) Check-up of the LDA cleaning pipeline output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a03e3fa3-7176-4634-ac66-023a835ecae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "möchten beschweren müllberge dreck grillgestank rücksichtslos laut musiklärm jedesmal schön wetter neubürger sippe westpark grillbereich unterhalb rosengarten verursachen\n",
      "\n",
      "RAW:\n",
      "Möchte mich beschweren über die Müllberge,den Dreck,den Grillgestank und den rücksichtslos lauten Musiklärm,den jedesmal bei schönem Wetter immer wieder die gleichen Neubürger mit ihrer ganzen Sippe im Westpark im Grillbereich unterhalb des Rosengartens verursachen!!Warum wird nichts dagegen getan?\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "laterne defekt höhe nordendstraße münchen\n",
      "\n",
      "RAW:\n",
      "Laterne defekt auf Höhe Nordendstraße 34, 80801 München\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "sperrmüll bachbett\n",
      "\n",
      "RAW:\n",
      "Sperrmüll im „Bachbett“\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "isartalbahnweg mast defekt\n",
      "\n",
      "RAW:\n",
      "Am Isartalbahnweg ist der Mast Nr. 9 defekt\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "lochhausener mastnummer lampe ausfallen\n",
      "\n",
      "RAW:\n",
      "Lochhausener Str. - Mastnummer 123 - T8-Lampe ausgefallen\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "wichtig haltezon eltern grundschule laufhaufe blockieren\n",
      "\n",
      "RAW:\n",
      "Leider wurden unsere wichtigen Haltezonen für die Eltern der Grundschule mit Laufhaufen blockiert.\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "laterne forstenried allee glimmen leuchtröhr rötlich\n",
      "\n",
      "RAW:\n",
      "Bei Laterne 106  vor Forstenrieder Allee 261 glimmen beide Leuchtröhren nur rötlich\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "fuss radweg lampe mast dunkel\n",
      "\n",
      "RAW:\n",
      "Auf dem Fuss - und Radweg , gleich die erste Lampe Mast 1 von der Strasse her ist dunkel\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "mast komplett dunkel\n",
      "\n",
      "RAW:\n",
      "Mast Nr. 13 komplett dunkel\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "hängeleucht leuchtstoffröhren defekt lampengla verschmutzen\n",
      "\n",
      "RAW:\n",
      "Bei Hängeleuchte: eine von beiden Leuchtstoffröhren defekt und Lampenglas verschmutzt \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from config import CLEANED_COMPLAINTS_FILE\n",
    "\n",
    "def preview_cleaning(n=10):\n",
    "    \"\"\"Print cleaned text above raw text for easy inspection.\"\"\"\n",
    "    df = pd.read_csv(CLEANED_COMPLAINTS_FILE)\n",
    "    sample = df[[\"description\", \"lda_description\"]].sample(n)\n",
    "\n",
    "    for i, row in sample.iterrows():\n",
    "        print(\"------ SAMPLE ------\")\n",
    "        print(\"CLEANED:\")\n",
    "        print(row[\"lda_description\"])\n",
    "        print(\"\\nRAW:\")\n",
    "        print(row[\"description\"])\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run it:\n",
    "preview_cleaning(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316051a-aaa2-4de0-ad5e-0c7c87e7cb2c",
   "metadata": {},
   "source": [
    "### (2) Check-up of the BERTopic cleaning pipeline output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a337ce7c-47db-4ed3-918f-06bfc21df755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "eine der hängeleuchten ist aus\n",
      "\n",
      "RAW:\n",
      "Eine der Hängeleuchten ist aus. \n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "an der sophienstr ist eine gehwegleuchte ausgefallen\n",
      "\n",
      "RAW:\n",
      "An der Sophienstr. ist eine Gehwegleuchte ausgefallen. \n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "man sieht das auf dem foto nicht so gut von den beiden lampen ist die linke defekt\n",
      "\n",
      "RAW:\n",
      "Man sieht das auf dem Foto nicht so gut. Von den beiden Lampen ist die linke defekt\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "straßenlaterne vor am westpark 8 neben der litfaßsäule funktioniert nicht\n",
      "\n",
      "RAW:\n",
      "Straßenlaterne vor Am Westpark 8 (neben der Litfaßsäule) funktioniert nicht.\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "am anfang der perhamerstraße von fürstenriederstr bis auf höhe lutzstraße ging in der nacht von 6 9 auf 7 9 24 keine einzige straßenlaterne\n",
      "\n",
      "RAW:\n",
      "Am Anfang der Perhamerstraße (von Fürstenriederstr. bis auf Höhe Lutzstraße) ging in der Nacht von 6.9. auf 7.9.24 keine einzige Straßenlaterne.\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "neuer grünstreifen vor westendstr 35 verwildert kann man dass nicht endlich mal gescheit gartenbau machen lass und mal einen baum pflanzen etc\n",
      "\n",
      "RAW:\n",
      "neuer Grünstreifen vor Westendstr 35 verwildert, kann man dass nicht endlich mal gescheit Gartenbau machen lass und mal einen Baum pflanzen etc.\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "kaiser ludwig platz richtung süden ampel über straße grün ausgefallen\n",
      "\n",
      "RAW:\n",
      "KAISER LUDWIG PLATZ Richtung Süden Ampel über Straße Grün ausgefallen\n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "ausgefallen\n",
      "\n",
      "RAW:\n",
      "Ausgefallen \n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "herrenloser einkaufswagen am ende guerickestr\n",
      "\n",
      "RAW:\n",
      "Herrenloser Einkaufswagen am Ende Guerickestr. \n",
      "\n",
      "\n",
      "------ SAMPLE ------\n",
      "CLEANED:\n",
      "müll unter der brücke hellabrunnseite\n",
      "\n",
      "RAW:\n",
      "Müll unter der Brücke, Hellabrunnseite\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from config import CLEANED_COMPLAINTS_FILE\n",
    "\n",
    "def preview_cleaning(n=10):\n",
    "    \"\"\"Print cleaned text above raw text for easy inspection.\"\"\"\n",
    "    df = pd.read_csv(CLEANED_COMPLAINTS_FILE)\n",
    "    sample = df[[\"description\", \"bertopic_description\"]].sample(n)\n",
    "\n",
    "    for i, row in sample.iterrows():\n",
    "        print(\"------ SAMPLE ------\")\n",
    "        print(\"CLEANED:\")\n",
    "        print(row[\"bertopic_description\"])\n",
    "        print(\"\\nRAW:\")\n",
    "        print(row[\"description\"])\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run it:\n",
    "preview_cleaning(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e750dc5-71e4-4c37-9362-dc24b5ce6ca9",
   "metadata": {},
   "source": [
    "## Vectorization Checkups (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2103029c-859b-4fe8-8c47-853cd793f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root set to: /Users/dd/PycharmProjects/complaints_analysis\n",
      "Working directory: /Users/dd/PycharmProjects/complaints_analysis\n",
      "src/ added to sys.path\n"
     ]
    }
   ],
   "source": [
    "# ===== Project path bootstrap (RUN ONCE) =====\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Resolve project root assuming this notebook is in /notebooks/\n",
    "PROJECT_ROOT = Path.cwd().parents[0]\n",
    "\n",
    "# Add src/ to Python path for module imports\n",
    "SRC_PATH = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_PATH) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_PATH))\n",
    "\n",
    "# Change working directory to project root (for relative file paths)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root set to:\", PROJECT_ROOT)\n",
    "print(\"Working directory:\", Path.cwd())\n",
    "print(\"src/ added to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbf7ac1-f597-4e4c-86cb-b8bb0b5607bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect feature names (vocabulary sanity check)\n",
    "\n",
    "import joblib\n",
    "\n",
    "bow_vocab = joblib.load(\"data/vectorized/lda/lda_bow_feature_names.joblib\")\n",
    "tfidf_vocab = joblib.load(\"data/vectorized/lda/lda_tfidf_feature_names.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a904c4-9fd3-4f1b-8344-2b6050ee333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbauen',\n",
       " 'abbrechen',\n",
       " 'abdeckung',\n",
       " 'abend',\n",
       " 'abends',\n",
       " 'abfall',\n",
       " 'abfluss',\n",
       " 'abgefallen',\n",
       " 'ablauf',\n",
       " 'ablegen',\n",
       " 'abschaltung',\n",
       " 'abschnitt',\n",
       " 'absperrung',\n",
       " 'abstellen',\n",
       " 'agnesstr',\n",
       " 'allee',\n",
       " 'alt',\n",
       " 'ampel',\n",
       " 'ampelanlage',\n",
       " 'anderer',\n",
       " 'andrea',\n",
       " 'anfang',\n",
       " 'anforderung',\n",
       " 'angebracht',\n",
       " 'angefahr',\n",
       " 'anlage',\n",
       " 'ansehen',\n",
       " 'anwesen',\n",
       " 'art',\n",
       " 'ast',\n",
       " 'aufbauen',\n",
       " 'auffüllen',\n",
       " 'aufgang',\n",
       " 'aufhängen',\n",
       " 'aufkleber',\n",
       " 'aufstellen',\n",
       " 'augustiner',\n",
       " 'ausfahrt',\n",
       " 'ausfall',\n",
       " 'ausfallen',\n",
       " 'ausgang',\n",
       " 'ausgebrannt',\n",
       " 'ausgefall',\n",
       " 'ausgefalle',\n",
       " 'ausgefallen',\n",
       " 'ausgehen',\n",
       " 'ausleger',\n",
       " 'ausleuchten',\n",
       " 'ausreichend',\n",
       " 'ausschließlich']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vocab[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea7019c-1505-405b-84b7-5d2940589200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbauen',\n",
       " 'abbrechen',\n",
       " 'abdeckung',\n",
       " 'abend',\n",
       " 'abends',\n",
       " 'abfall',\n",
       " 'abfluss',\n",
       " 'abgefallen',\n",
       " 'ablauf',\n",
       " 'ablegen',\n",
       " 'abschaltung',\n",
       " 'abschnitt',\n",
       " 'absperrung',\n",
       " 'abstellen',\n",
       " 'agnesstr',\n",
       " 'allee',\n",
       " 'alt',\n",
       " 'ampel',\n",
       " 'ampelanlage',\n",
       " 'anderer',\n",
       " 'andrea',\n",
       " 'anfang',\n",
       " 'anforderung',\n",
       " 'angebracht',\n",
       " 'angefahr',\n",
       " 'anlage',\n",
       " 'ansehen',\n",
       " 'anwesen',\n",
       " 'art',\n",
       " 'ast',\n",
       " 'aufbauen',\n",
       " 'auffüllen',\n",
       " 'aufgang',\n",
       " 'aufhängen',\n",
       " 'aufkleber',\n",
       " 'aufstellen',\n",
       " 'augustiner',\n",
       " 'ausfahrt',\n",
       " 'ausfall',\n",
       " 'ausfallen',\n",
       " 'ausgang',\n",
       " 'ausgebrannt',\n",
       " 'ausgefall',\n",
       " 'ausgefalle',\n",
       " 'ausgefallen',\n",
       " 'ausgehen',\n",
       " 'ausleger',\n",
       " 'ausleuchten',\n",
       " 'ausreichend',\n",
       " 'ausschließlich']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vocab[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b44c80-c777-4c09-899e-4fe9bd87c291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ausfallen</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>defekt</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>leuchte</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>mast</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>brunnen</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>lampe</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>leuchten</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>komplett</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>laterne</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>beleuchtung</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>dunkel</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ecke</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>licht</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>funktionieren</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>liegen</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>wasser</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>vieler</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>platz</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>laufen</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>richtung</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>woche</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>direkt</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>stehen</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>fehlen</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ampel</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>müll</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>weg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>höhe</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>beschädigen</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>verschmutzen</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  freq\n",
       "39       ausfallen   191\n",
       "117         defekt   132\n",
       "380        leuchte   126\n",
       "411           mast    92\n",
       "105        brunnen    90\n",
       "349          lampe    89\n",
       "381       leuchten    63\n",
       "336       komplett    59\n",
       "363        laterne    50\n",
       "77     beleuchtung    50\n",
       "129         dunkel    48\n",
       "131           ecke    47\n",
       "391          licht    41\n",
       "202  funktionieren    39\n",
       "394         liegen    39\n",
       "714         wasser    37\n",
       "701         vieler    37\n",
       "490          platz    34\n",
       "367         laufen    33\n",
       "517       richtung    33\n",
       "742          woche    32\n",
       "121         direkt    32\n",
       "602         stehen    31\n",
       "176         fehlen    30\n",
       "17           ampel    30\n",
       "441           müll    29\n",
       "717            weg    28\n",
       "300           höhe    28\n",
       "84     beschädigen    28\n",
       "694   verschmutzen    28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X = load_npz(\"data/vectorized/lda/lda_bow_matrix.npz\")\n",
    "freq = X.sum(axis=0).A1\n",
    "\n",
    "top = pd.DataFrame({\"token\": bow_vocab, \"freq\": freq}).sort_values(\"freq\", ascending=False)\n",
    "top.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847da092-c146-4b53-8411-82bcbc87bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002178649237472767, 0.2047930283224401)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Document frequency distribution\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "import numpy as np\n",
    "\n",
    "X = load_npz(\"data/vectorized/lda/lda_bow_matrix.npz\")\n",
    "doc_freq = np.asarray((X > 0).sum(axis=0)).ravel()\n",
    "doc_freq_ratio = doc_freq / X.shape[0]\n",
    "\n",
    "# Show some stats\n",
    "doc_freq_ratio.min(), doc_freq_ratio.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16467d64-54ee-427e-861b-f303bd805d5b",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "\t•\tThe least frequent terms appear in ~0.2% of documents (≈ 2 documents), matching the min_df=2 threshold.\n",
    "\t•\tThe most frequent term appears in ~20% of documents, indicating that no single token dominates the corpus.\n",
    "\n",
    "Assessment\n",
    "\t•\tThe vocabulary is well balanced:\n",
    "\t•\tRare terms are filtered appropriately.\n",
    "\t•\tOverly generic terms are successfully suppressed.\n",
    "\t•\tThe chosen min_df and max_df parameters are well calibrated for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6966979c-636d-4c62-add2-eb7827200ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ausfallen</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>defekt</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>leuchte</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>mast</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>brunnen</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>lampe</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>leuchten</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>komplett</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>laterne</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>beleuchtung</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>dunkel</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ecke</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>licht</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>funktionieren</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>liegen</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>wasser</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>vieler</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>platz</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>laufen</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>richtung</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  freq\n",
       "39       ausfallen   191\n",
       "117         defekt   132\n",
       "380        leuchte   126\n",
       "411           mast    92\n",
       "105        brunnen    90\n",
       "349          lampe    89\n",
       "381       leuchten    63\n",
       "336       komplett    59\n",
       "363        laterne    50\n",
       "77     beleuchtung    50\n",
       "129         dunkel    48\n",
       "131           ecke    47\n",
       "391          licht    41\n",
       "202  funktionieren    39\n",
       "394         liegen    39\n",
       "714         wasser    37\n",
       "701         vieler    37\n",
       "490          platz    34\n",
       "367         laufen    33\n",
       "517       richtung    33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "token_freq = X.sum(axis=0).A1\n",
    "top = pd.DataFrame({\n",
    "    \"token\": bow_vocab,\n",
    "    \"freq\": token_freq\n",
    "}).sort_values(\"freq\", ascending=False)\n",
    "\n",
    "top.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ae1d5-08ea-4e07-8ac3-148430cbf54c",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "\t•\tHigh-frequency terms clearly reflect core municipal issue themes, such as:\n",
    "\t•\tInfrastructure failures\n",
    "\t•\tStreet lighting\n",
    "\t•\tTraffic signals\n",
    "\t•\tWater features and waste\n",
    "\t•\tNo obvious noise tokens or stopword leakage are present.\n",
    "\n",
    "Assessment\n",
    "\t•\tThe vocabulary preserves domain-relevant semantics.\n",
    "\t•\tThe preprocessing and vectorization steps successfully retained meaningful signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291d39a6-293b-4b80-8242-b4a3477e0ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4.994553376906318, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparisty per document\n",
    "tokens_per_doc = (X > 0).sum(axis=1).A1\n",
    "\n",
    "tokens_per_doc.min(), tokens_per_doc.mean(), tokens_per_doc.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea7484-3db7-413c-8e78-f6a8e12cbeef",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "\t•\tThe complaints are short texts, with an average of ~5 tokens per document after cleaning.\n",
    "\t•\tA small number of documents contain only a single token (e.g. “ausgefallen”), which is typical for municipal issue reports.\n",
    "\t•\tSome longer descriptions (up to 40 tokens) exist and provide richer context, which helps stabilize topic modeling.\n",
    "\n",
    "Assessment\n",
    "\t•\tThis distribution is expected for Open311-style complaint data.\n",
    "\t•\tWhile short documents can limit topic granularity, the dataset still contains sufficient semantic signal.\n",
    "\t•\tNo additional filtering is required at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a559e243-c65d-484b-b850-cec5b4068c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.994553376906318\n",
      "4.994553376906318\n"
     ]
    }
   ],
   "source": [
    "X_tfidf = load_npz(\"data/vectorized/lda/lda_tfidf_matrix.npz\")\n",
    "\n",
    "print(X.nnz / X.shape[0])\n",
    "print(X_tfidf.nnz / X_tfidf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f828b5-e45b-40f3-8ccd-6c9275262ef9",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "\t•\tBoth Bag-of-Words and TF-IDF representations contain the same number of non-zero entries per document.\n",
    "\t•\tThis confirms that TF-IDF reweights terms but does not alter the underlying sparsity structure.\n",
    "\n",
    "Assessment\n",
    "\t•\tThe two vectorization techniques are directly comparable.\n",
    "\t•\tAny differences in topic modeling results will be attributable to term weighting, not preprocessing artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c39f6b6d-09cb-4893-a237-7b14847056ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ausfallen', 0.06811506872020248),\n",
       " ('leuchte', 0.058020352149674055),\n",
       " ('defekt', 0.05137879254587185),\n",
       " ('mast', 0.03719220622876415),\n",
       " ('lampe', 0.03266920163313266),\n",
       " ('leuchten', 0.025904562939074605),\n",
       " ('komplett', 0.02475369719785844),\n",
       " ('brunnen', 0.024453050065529985),\n",
       " ('licht', 0.02412279608641433),\n",
       " ('beleuchtung', 0.022306561459963202),\n",
       " ('dunkel', 0.018957822436670102),\n",
       " ('laterne', 0.018735438419480988),\n",
       " ('funktionieren', 0.014851177203165426),\n",
       " ('röhre', 0.01484489983295294),\n",
       " ('straßenlaterne', 0.014173669174849659),\n",
       " ('ecke', 0.014074454660146923),\n",
       " ('liegen', 0.01403574448520288),\n",
       " ('fehlen', 0.013021792220663526),\n",
       " ('ampel', 0.012847347302876951),\n",
       " ('höhe', 0.012512371305062315)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_means = np.asarray(X_tfidf.mean(axis=0)).ravel()\n",
    "top = np.argsort(tfidf_means)[-20:]\n",
    "[(tfidf_vocab[i], tfidf_means[i]) for i in reversed(top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398933be-fb43-411b-a9d7-156d2533d0bf",
   "metadata": {},
   "source": [
    "**TF-IDF Feature Inspection — Interpretation**\n",
    "\n",
    "The listed terms have the highest **average TF-IDF scores** across documents, meaning they are\n",
    "globally informative rather than just frequent.\n",
    "\n",
    "- Dominated by **domain-specific failure terms** (*ausfallen, defekt, leuchte, lampe*).\n",
    "- No generic stopwords → **cleaning and vectorization are effective**.\n",
    "- Strong semantic coherence around **infrastructure faults and lighting**.\n",
    "- High overlap with BoW results → **stable and consistent feature space**.\n",
    "\n",
    "**Conclusion:**  \n",
    "TF-IDF features are well-formed and suitable for LDA topic modeling. No changes needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
